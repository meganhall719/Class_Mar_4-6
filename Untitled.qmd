---
title: "March 4 Notes In Class"
format: html
editor: visual
---

## In Class March 4th

### In Class more on infer

offers a convenient set of functions and a standard worfklow for using permutation methods fro hypothesis testing, whether we are dealing with means, differences between means, proportions, or differences in proportions.

Specify something we are interested in in the data –\> hypothesize something on that data —\> generate data —\> calculate data —\> visualize

```{r}
library(dplyr)
library(tibble)
library(infer)
library(tidyverse)
f <-"https://raw.githubusercontent.com/difiore/ada-datasets/main/tbs-2006-2008-ranges.csv"
d <- read_csv(f, col_names = TRUE)
d 
head(d)
view(d)
```

1.  We first use the function *specify()* to indicate the variables we are interested in.

    ```{r}
    d <- d |>
    specify(formula = kernel95 ~ sex)
    ```

2.  The function hypothesize() is then used to declare the null hypothesis we wish to test.

    ```{r}
    d <- d |>
    hypothesize(null = "independence")
    ```

3.  We then use the *generate() function* to generate replicates of “permuted” data under the assumption that the null hypothesis is true.

    ```{r}
    perm <- d |>
      generate(reps = 1000, type = "permute")
    ```

4.  Next, we use calculate() to calculate summary statistics of interest for each replicate.

```{{r}}
perm <- perm |>
calculate(stat = "diff in means", order = c("M", "F"))

```

5.  We can then use the function visualize() to examine the null distribution

    ```{r}
    visualize(perm, bins = 20)

    ```

All together

```{r}
d <- d |>
specify(formula = kernel95 ~ sex)
d <- d |>
hypothesize(null = "independence")
perm <- d |>
  generate(reps = 10000, type = "permute")

perm <- perm |>
calculate(stat = "diff in means", order = c("M", "F"))
visualize(perm, bins = 20)
```

Visualize permutation distribution

-   observe

    ```{r}
    #observation
    obs <- d |>
    specify(kernel95 ~ sex) |>
    calculate(stat = "diff in means", order = c("M", "F"))
    #visualize 
    visualize(perm, bins = 20) +
    shade_p_value(obs_stat = obs, direction = "both")

    get_p_value(perm, obs, direction = "both")
    #pvalue very small we reject the null hypothesis that there is no association based on sex 

    ```

**permutation distribution should be 0 centered**

-   **take the mean of permutation**

```{r}
mean(perm$stat)
```

Another package called {modelr}

## Shifting gears : Regression

```{r}
library(tidyverse)
library(infer)
library(manipulate)
library(patchwork)
library(lmodel2)
library(sjPlot)
library(broom)
```

### [Regression: common form of data modeling]{.underline}

explore the relationship between an outcome variable (typically denotes as y)

[**Simple(general) Linear regression**]{.underline}

response variable is a typical numerical or categorical variable

[**Multiple (general) linear regression**]{.underline}

outcome is a continuous numerical variable, multiple predictors that are either numerical or categorical

[**ANOVA/ANCOVA**]{.underline}

focuses on categorical predictors

--\> Really focuses on categorical predictors

[**Generalized linear regression**]{.underline}

allows for binary categorical count variables as outcomes

--\> covid test postitive or negative

### Start with exploratory data analysis

Univariate summary statistics skim() {skimr}

### Bivariate summary statistics

-   **covaraince** how much two numerical variables "change together" and whether that change is positive or negative

-   **Correlation coefficient** is a standardized form of the vocation that summarizes, on a scale from -1 to +1 both the strength

-   **correlation coefficient** two is a standardize covariance (divide by the product of the standard deviations of the two variables

    ```{r}
    # loading dataset 
    f <- "https://raw.githubusercontent.com/difiore/ada-datasets/main/zombies.csv"
    d <- read_csv(f, col_names = TRUE)
    head(d)

    h <-d$height - mean(d$height)
    w<-d$weight - mean(d$weight)


    #plot the realationship between zombie apocalypse survivor weight and zombie apocalypse survivor height 
    cov <-sum(h*w)/(length(d$height)-1)


    # covaraince function 
    cov(d$height, d$weight)

    #correlation
    cor<-cov/(sd(d$height)*sd(d$weight))
    cor(d$height, d$weight)

    #plot
    plot(d$height,d$weight)
    ```

## Purpose for Regression

-   predict the value of an outcome variable y based on the information contained in a set of predictor variables x

-   describe and quantify the relationship between the outcome variable y and a set of explanatory variables z

-   develop and choose among different models

-   analyze co variation among sets of variables to identify/explore their relative explanatory power

-   determine causality

## Formula

model the outcome variable y "as a linear function" : of the explanatory/predictor variables

![](images/Screenshot%202025-03-04%20at%204.37.07%20PM.png){width="205" height="34"}

Beta values in this equation are referred to as "regression coefficients" and it is those coefficients that our analysis are trying to estimate. Usually trying to minimize error

Ordinary Least squares

```{r}
library(manipulate)
#fine the. line of best fit and minimizing the sum of squares in y varaible / response varaible

d <- mutate(d, centered_height = height - mean(height))
d <- mutate(d, centered_weight = weight - mean(weight))
mean(d$centered_height)

#slope.test 
slope.test <- function(beta1, data) {
    g <- ggplot(data = data, aes(x = centered_weight, y = centered_height))
    g <- g + geom_point()
    g <- g + geom_abline(intercept = 0, slope = beta1, size = 1, colour = "blue",
        alpha = 1/2)
    ols <- sum((data$centered_height - beta1 * data$centered_weight)^2)
    g <- g + ggtitle(paste("Slope = ", beta1, "\nSum of Squared Deviations = ", round(ols,
        3)))
    g
}

#manipulate statement
manipulate(slope.test(beta1, data = d), beta1 = slider(-1, 1, initial = 0, step = 0.005))
```

```         
```
